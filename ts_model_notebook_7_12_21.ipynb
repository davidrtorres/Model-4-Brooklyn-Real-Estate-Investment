{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cQYuKwNMN4B-"
   },
   "source": [
    "By:  David R. Torres<br>\n",
    "Flatiron School<br>\n",
    "Github repo: https://github.com/davidrtorres/dsc-mod-4-project-v2-1-onl01-dtsc-pt-041320/tree/master"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CJtzem1QCZLa"
   },
   "source": [
    "# **Using an ARIMA Model for Time Series Forecasting**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M3f3mRul-rQB"
   },
   "source": [
    "### **Introduction**\n",
    "Business Problem: I am a consultant for Premium Real Estate, LLC.  The firm asked me to provide analysis and recommendations for investing in real estate in the top 5 zipcodes in Brooklyn, NY that will provide the highest return on investment.  The investment firm is looking for short-term investments with the highest returns over a 3 year period.  The investment firm isn't looking for long term investments.<br>\n",
    "<br>\n",
    "I will make recommendations based on the real estate prices in Brooklyn. The top 5 zipcodes or 'best' zipcodes will be those with the highest ROI over the 3 year period.<br>\n",
    "<br>\n",
    "For the task, I analyzed real estate sales data from Zillow which covers the time period 4-1-1996 to 4-1-2018.<br>\n",
    "I used an Auto Arima model to conduct a gridsearch and find the p,d,qs and Seasonal P,D,Qs with the lowest related AIC scores for each zipcode.  I used a SARIMA model to make predictions regarding the test data.  I used the metric RMSE to evaluate how my models were performing in making predictons.  I then made models to perform dynamic forecasts for 3 years.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0Hrqf3EGbiTQ",
    "outputId": "cd270874-e52c-4c29-8a8b-d3ad0f315724"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook 12-18-20\n"
     ]
    }
   ],
   "source": [
    "print('Notebook 12-18-20')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import itertools\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4jpCp8ADcCT3"
   },
   "outputs": [],
   "source": [
    "zillow = pd.read_csv('https://raw.githubusercontent.com/learn-co-students/dsc-mod-4-project-v2-1-onl01-dtsc-ft-070620/master/time-series/zillow_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 304
    },
    "id": "jII7ir55biTZ",
    "outputId": "6140ac7b-a8ac-4bc4-b3f7-d90b15bb7f94"
   },
   "outputs": [],
   "source": [
    "zillow.rename(columns={'RegionName': 'Zipcode'}, inplace=True)\n",
    "zillow.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vW2YFMRwxE_f"
   },
   "source": [
    "## Preprocessing Data\n",
    "### Melted Data Function\n",
    "The dataset is from Zillow.com so I had to first reshape the data frame from wide to long format using the function .melt() and then transform it into a time series data frame.  Then I created a subset of the dataframe for only properties located under column 'State' of 'NY' and column 'CountyName' of 'Kings'.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YKnocApwbiTd"
   },
   "outputs": [],
   "source": [
    "def melt_data(df):\n",
    "    \"\"\"\n",
    "    df - is the dataframe\n",
    "    This is a time series so I need a column for dates to become the index.\n",
    "    .melt() function sets up dataframe so date columns can be merged as a single column.  \n",
    "    \"\"\"\n",
    "    melted = pd.melt(df, id_vars=['RegionID','Zipcode', 'City', 'State', 'Metro', 'CountyName', \n",
    "                                  'SizeRank'], var_name='Month', value_name='MeanValue')\n",
    "    melted['Month'] = pd.to_datetime(melted['Month'], format='%Y-%m')\n",
    "    #melted = melted.set_index('Month')\n",
    "    melted = melted.dropna(subset=['MeanValue'])\n",
    "    return melted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZNb6xx_sbiTg"
   },
   "outputs": [],
   "source": [
    "all_zipcodes = melt_data(zillow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HNJOEqCPbiTj",
    "outputId": "8e346e0c-d050-435a-c5b2-f69dd85fc46f"
   },
   "outputs": [],
   "source": [
    "all_zipcodes.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "id": "WSfg2hYlbiTn",
    "outputId": "adfeddcc-409e-4f49-8292-0989a48a2703",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_zipcodes.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "W-nMbgDpbiTr",
    "outputId": "7ce379a7-f1ee-416d-9979-7ef04a05da0b"
   },
   "outputs": [],
   "source": [
    "kings_zips = all_zipcodes[(all_zipcodes['CountyName']=='Kings') & (all_zipcodes['State']== 'NY')]\n",
    "kings_zips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "69cDi609biTu"
   },
   "outputs": [],
   "source": [
    "#for loop gets the monthly mean sales price for each Brooklyn zipcode and puts it in dictionary. \n",
    "\n",
    "test_dict = {}\n",
    "\n",
    "for zipcode in kings_zips['Zipcode'].unique(): \n",
    "    all_zips = kings_zips[kings_zips['Zipcode'] == zipcode]\n",
    "    all_zips = all_zips.set_index('Month')['MeanValue']\n",
    "    all_zips = all_zips.asfreq('MS')\n",
    "    all_zips.name = zipcode\n",
    "    test_dict[zipcode] = all_zips\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yJyLlWG8biTx",
    "outputId": "d4be46b8-51b2-4f36-e7d2-d2a0d355d4aa"
   },
   "outputs": [],
   "source": [
    "test_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z3d1JXotbiT1"
   },
   "outputs": [],
   "source": [
    "zip_df = pd.concat(test_dict, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YKPSazbabiT4",
    "outputId": "07811b6e-a9fe-4c01-e423-e76f8c091cb5"
   },
   "outputs": [],
   "source": [
    "len(zip_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LRrvB7R75NTO"
   },
   "source": [
    "### **Dataframe of Brooklyn Zipcodes** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After pre-processing the data I limited the scope of my search to real property in Brookyln, NY.  These\n",
    "properties were identified in the dataframe under 'CountyName' as 'King'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rLu9DH6Muc67",
    "outputId": "921d23f4-7911-46b5-9800-6a020e454b45"
   },
   "outputs": [],
   "source": [
    "type(zip_df[11226])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "id": "lejk8RxHbiT7",
    "outputId": "b7ec0a9a-c2f2-4f11-bbdd-bd4346528120"
   },
   "outputs": [],
   "source": [
    "zip_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "id": "Wrw_HAgLbiT-",
    "outputId": "0b270185-9f29-4140-c5af-2e7df5f98d7f"
   },
   "outputs": [],
   "source": [
    "zip_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "87SNbfDNCTpq",
    "outputId": "2da44572-8ed9-44cf-f300-472db7e30167"
   },
   "outputs": [],
   "source": [
    "len(zip_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YuHJxkLobiUC",
    "outputId": "534c5264-6097-42c9-eb20-9d8c0a229671"
   },
   "outputs": [],
   "source": [
    "zip_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ngeo31_HbiUG",
    "outputId": "6ce6bb0f-cde9-45e5-f4bd-45febfb5d1fa"
   },
   "outputs": [],
   "source": [
    "zip_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EASqYe0Iu0_6"
   },
   "source": [
    "#### **NaN Values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gJ_gRsqNbiUP"
   },
   "outputs": [],
   "source": [
    "zip_df.bfill(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4K3fVTrf_c6z",
    "outputId": "730d4a67-d2c4-463c-e0b8-e0c8f878be25"
   },
   "outputs": [],
   "source": [
    "zip_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zfzxZv8MbiUS",
    "outputId": "c6a34f9d-1bd4-46a4-ab7d-479648dfaa7a"
   },
   "outputs": [],
   "source": [
    "zip_df[11238].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YB3wd8s4biUV",
    "outputId": "e4204c37-f197-4547-b9ef-493fd12dae40"
   },
   "outputs": [],
   "source": [
    "zip_df.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zS3cFsAR7BzS",
    "outputId": "dca5787b-4712-476b-b12e-544f3b1afd93"
   },
   "outputs": [],
   "source": [
    "zip_df[11238].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nswxNI8rRCwx"
   },
   "source": [
    "### **Plot of Price Trends of Brooklyn Zipcodes**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a plot of the time series data for each zip code demonstrating the price trends.  There are 28 zipcodes.  An overall upward trend can be observed from the years 1996 to 2018.  Regarding the housing bubble, we can see in the plot that housing prices peaked in early 2006, started to decline in 2006 and 2007, and then reached lows in 2012.<br>\n",
    "The top 5 zip codes have consistently been top 5 performers for around 14 years.  The bottom 3 zipcodes displayed little change in price over time compared to top priced zip codes.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_df.plot(figsize=(12,8))\n",
    "plt.title(\"Housing Price Trends \")\n",
    "#plt.set(title=f'Housing Prices by Year - {zip_df.index.freq}')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Brooklyn Real Estate Price Trends for Zipcodes')\n",
    "plt.legend(bbox_to_anchor=(1.05,1),loc='upper left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot of top 6 zipcodes with highest sale prices over extended periods. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "IzMDX4LeVQgn",
    "outputId": "02fe9bab-9737-4350-b221-10cebbf52337"
   },
   "outputs": [],
   "source": [
    "zip_df_1 = zip_df[[11217, 11238,11215,11216,11222,11205]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 530
    },
    "id": "wGnxTXmCbiUZ",
    "outputId": "c5839245-9e31-499d-870c-fc4204c6a809"
   },
   "outputs": [],
   "source": [
    "zip_df_1.plot(figsize=(12,8))\n",
    "plt.title(\"Top 6 Zipcodes With Highest Real Estate Prices\")\n",
    "#plt.set(title=f'Housing Prices by Year - {zip_df.index.freq}')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Home Prices')\n",
    "plt.legend(bbox_to_anchor=(1.05,1),loc='upper left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X5YrChO88Rs5"
   },
   "source": [
    "Zipcodes: 11217, 11238, 11205 had the same values for monthly real easte so I created a plot eliminating these dates.  <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 450
    },
    "id": "hK18KcJ94w9d",
    "outputId": "f6fb1f99-3962-49cf-8996-c20758d1b8f8"
   },
   "outputs": [],
   "source": [
    "zip_no_nan = zip_df_1['2003-12-01':] \n",
    "zip_no_nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 530
    },
    "id": "CFkJV9N-5Cw9",
    "outputId": "61863eaa-921a-4236-f14a-e7d955c08338"
   },
   "outputs": [],
   "source": [
    "zip_no_nan.plot(figsize=(12,8))\n",
    "plt.title(\"Housing Price Trends \")\n",
    "#plt.set(title=f'Housing Prices by Year - {zip_df.index.freq}')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Home Prices')\n",
    "plt.legend(bbox_to_anchor=(1.05,1),loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "id": "LOT5jY4jhLb6",
    "outputId": "e50594ff-7f2c-44f8-dff2-575d442a4d38"
   },
   "outputs": [],
   "source": [
    "zip_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "20YZOH-pEZHr"
   },
   "source": [
    "### **Train/Test Split**\n",
    "The zip_df dataset will be split into train and test sets to be used as inputs for the models.  Train data set is from 1996–04–01 to 2014–01–01. The length of our train data set is 214 rows, or 214 time periods.<br>\n",
    "Test data set is from 2014–01–01 to 2018–04–01. The length of the test data is 52 rows, or 52 time periods. \n",
    "That is the value will use for our .predict() method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cha0zTs-biUc"
   },
   "outputs": [],
   "source": [
    "year = '2014-01-01'\n",
    "train_brk = zip_df.loc[:year]\n",
    "#test_brk = zip_df.loc[year:]\n",
    "test_brk = zip_df.loc['2014-01-02':]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IXnnCEIVbiUf",
    "outputId": "317bca91-3cbe-4d87-caaf-e2970a77f45f"
   },
   "outputs": [],
   "source": [
    "print(len(zip_df))\n",
    "print(train_brk.shape)\n",
    "print(test_brk.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "id": "BbwT-gkwG8pF",
    "outputId": "5ca02075-93c9-4bc7-c1e3-a4c448aff728"
   },
   "outputs": [],
   "source": [
    "train_brk.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "id": "tnUO2YYy3KVt",
    "outputId": "9e717a8d-10b2-4a5b-e308-e1c73401ac12"
   },
   "outputs": [],
   "source": [
    "test_brk.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "id": "xiGyadLfgAnD",
    "outputId": "dce75625-3f27-453b-a1ad-14cda110af77"
   },
   "outputs": [],
   "source": [
    "test_brk.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_brk[11238][[0,-1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2sHi7PMpykLU"
   },
   "source": [
    "## **Auto_Arima Model**\n",
    "Why use an Auto_ARIMA model?  We use the auto-ARIMA process because it identifies the optimal parameters for an ARIMA model.  In order to use an ARIMA model it is essential that p,d,q values are inputted into the model.  Generally for an ARIMA model statisical techniques are used to generate these values by performing the difference to eliminate the non-stationarity and obtaining values from ACF and PACF plots.  I would add that the ACF and PACF plots are hard to interpret.<br>\n",
    "\n",
    "What do p,d and q represent?  The p is the parameter associated with the auto-regressive aspect of the model, which incorporates past values.  For example, forecasting that if it rained a lot over the past few days it's likely that it will rain tomorrow as well.<br>  \n",
    "The d is the parameter associated with the integrated part of the model, which effects the amount of differencing to apply to a time series, i.e., forecasting that the amount of rain tomorrow will be similar to the amount of rain today, if the daily amounts of rain have been similar over the past few days.<br>\n",
    "\n",
    "The q is the parameter associated with the moving average part of the model.<br>\n",
    "\n",
    "In the auto ARIMA, the P,D, and Q describe the same associations as p,d, and q, but correspond with the seasonal components of the model.<br>\n",
    "The auto ARIMA works similar to a grid search to find the optimal values for p, d, and q. The auto ARIMA iterates through all possible combinations of the p,d,q values for each zip code to find out which combination produces the model with the lowest AIC score (best fit).  The final combination of parameters for each zipcode would be determined according the lowest AIC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eiGr0NJ8biUq"
   },
   "outputs": [],
   "source": [
    "import six\n",
    "import sys\n",
    "sys.modules['sklearn.externals.six'] = six"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 599
    },
    "id": "WfPzSzhPeMxS",
    "outputId": "5b5b89dc-e358-44a2-d6fe-201340f8280f"
   },
   "outputs": [],
   "source": [
    "!pip install pmdarima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DvupPiHBbiUt"
   },
   "outputs": [],
   "source": [
    "import six\n",
    "import joblib\n",
    "import sys\n",
    "sys.modules['sklearn.externals.six'] = six\n",
    "sys.modules['sklearn.externals.joblib'] = joblib\n",
    "import pmdarima as pm\n",
    "from pmdarima import auto_arima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y-IO0XR0biUy"
   },
   "outputs": [],
   "source": [
    "def arima_model(df):\n",
    "    \"\"\"\n",
    "    df- dataframe\n",
    "    function is a gridsearch to get optimal p,d,qs and lowest AIC for the model.\n",
    "    q-is moving average\n",
    "    \"\"\"\n",
    "    autoarima_model = auto_arima(df, start_p = 0, start_q = 0, #start_q = 0\n",
    "                              test='adf',             # use adftest to find optimal 'd'\n",
    "                              max_p = 3, max_q = 3,   # maximum p and q\n",
    "                              m = 12,                  #frequency of series \n",
    "                              d = None,               # let model determine 'd', was 1\n",
    "                              seasonal = True, \n",
    "                              start_P=0, D=1, trace = False, #start  #trace= True\n",
    "                              error_action ='ignore',   # we don't want to know if an order does not work \n",
    "                              suppress_warnings = True,  # we don't want convergence warnings \n",
    "                              stepwise = True)           # set to stepwise  \n",
    "       \n",
    "    return autoarima_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gVj63y1ObiU2"
   },
   "outputs": [],
   "source": [
    "stepwise_fit = arima_model(train_brk[11226])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 482
    },
    "id": "EAlk0GeubiU5",
    "outputId": "48805433-5317-4a12-bf7f-34173354c7b0"
   },
   "outputs": [],
   "source": [
    "stepwise_fit.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9sB-cPoAF5Qw"
   },
   "source": [
    "### **Dataframe of p,d,qs, Seasonal p,d,qs and lowest AIC**\n",
    "The for loop iterates through the Brooklyn zipcodes dataframe (zip_df) and uses the arima_model function to get the best fit parameters (p,d,qs, Seasonal p,d,qs) and lowest AICs for each Brooklyn zipcode.  The list, arima_list, is then converted into a Pandas dataframe.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 917
    },
    "id": "YUSiFW3MIHdV",
    "outputId": "c8d108f6-0f01-45d4-8b5d-b8b3fc421054"
   },
   "outputs": [],
   "source": [
    "arima_list = [['zipcode', 'pdq','seasonal_pdq','aic']] \n",
    "for col in zip_df.columns:\n",
    "  zip_data = arima_model(zip_df[col])\n",
    "  arima_list.append([col,zip_data.order, zip_data.seasonal_order, zip_data.aic()])\n",
    "#result   \n",
    "output_df = pd.DataFrame(arima_list[1:],columns=arima_list[0]) \n",
    "output_df  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rxybUHbBZDar"
   },
   "source": [
    "### **Dataframe of PDQs, Seasonal PDQs and AICs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 917
    },
    "id": "wEW6x65SgU5a",
    "outputId": "6dee701a-1f5a-4807-fbb1-5268fc702ca5"
   },
   "outputs": [],
   "source": [
    "output_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9nCuBStdpptV"
   },
   "source": [
    "## **SARIMA Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o0_z6kcVT5sT"
   },
   "source": [
    "### **Fitting a SARIMA Time Series Model**\n",
    "Using a grid search approach, I used the Auto_Arima model to identify the set of optimal parameters to produce the best fitting model of the time series data.  The optimal parameter values are then inputted into the SARIMAX model.  I used a SARIMAX model because it takes into account trends and seasonality.  Acordingly, we can model our data without differencing it and addressing the issue of whether data is stationary or not.<br>    \n",
    "\n",
    "Coef column shows the importance of each feature and how each one impacts the time series patterns. \n",
    "The P>|z| provides the significance of each feature weight.<br>\n",
    "\n",
    "If a weight has a p-value lower or close to 0.05 it is reasonable to retain it in the model.<br>\n",
    "\n",
    "Model diagnostics - the purpose is to ensure that residuals remain uncorrelated, normally distributed having zero mean.  N(0,1)) is the standard notation for a normal distribution with mean 0 and standard deviation of 1).  This is a good indication that the residuals are normally distributed.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CI-u7raor5KT"
   },
   "outputs": [],
   "source": [
    "def fit_ARIMA(df, order=None, seasonal_order=None):\n",
    "    \"\"\"\n",
    "    forecasting statsmodel SARIMAX model\n",
    "    \"\"\"\n",
    "    ARIMA_MODEL = sm.tsa.statespace.SARIMAX(df, \n",
    "                                        order=order, \n",
    "                                        seasonal_order=seasonal_order, \n",
    "                                        enforce_stationarity=False, \n",
    "                                        enforce_invertibility=False)\n",
    "\n",
    "    # Fit the model and print results\n",
    "    output = ARIMA_MODEL.fit()\n",
    "\n",
    "    #display / no tables 1\n",
    "    display(output.summary())\n",
    "    \n",
    "    print('\\n')\n",
    "    print('MODEL DIAGNOSTICS')\n",
    "    \n",
    "    output.plot_diagnostics(figsize=(15, 18));\n",
    "    plt.show()\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kn2YvJbJW69c"
   },
   "source": [
    "## **Validating the Model**\n",
    "We're going to see how good our ARIMA model is at forecasting the sale price of homes located in zipcode 11128."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pnDW2sDjXQ4k"
   },
   "source": [
    "### **One-Step-Ahead Forecasting**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One Step Ahead forecasting means that forecasts at each point are generated using the full history data up to that point to make the prediction.  This allows us to evaluate how good our model is at predicting just one value ahead. \n",
    "\n",
    "In order to validate the model, I started by comparing predicted values to real values of the time series.  This will help us understand the accuracy of our forecasts.  I picked zip code 11218 as an example.<br>\n",
    "\n",
    "The methods .get_prediction() and .conf_int()  allow us to obtain the values and related confidence intervals for the time series forecasts.  The method .get_prediction generates in sample predictions and requires a date so that predictions will be made based on the data up to 1/1/2014. The model is going to make a prediction from the known values.  For this part I wil be  working with the whole dataset and not the train or test sets.<br>\n",
    "\n",
    "I set the dynamic parameter to false so that the model produces one-step ahead visuals.  The method .conf_int gives us the upper and lower limits on the values of our predictions of the 'pred' object.  This will generate a dataframe of the upper and lower uncertainty range of our prediction. \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Diagnostics\n",
    "In the fit_arima function I included the method '.plot_diagnostics()' to run on the ARIMA output  for a plot of the diagnostics to ensure that none of the assumptions are met. \n",
    "\n",
    "The method '.plot_diagnostics()' enables us to confirm whether the residuals remain uncorrelated and normally distributed having zero mean. In the absence of these assumptions, we can not move forward and need further tweaking of the model.\n",
    "\n",
    "The qq-plot on the bottom left shows that for the most part the ordered distribution of residuals (blue dots) follows the linear trend of the samples taken from a standard normal distribution with N(0, 1).  This is a strong indication that the residuals are normally distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "zPItuqTwr44f",
    "outputId": "f1a65dc1-ee48-4672-fad4-f7addb15ffef"
   },
   "outputs": [],
   "source": [
    "zipcode_osa = 11218\n",
    "zip_params= output_df[output_df['zipcode']==zipcode_osa]\n",
    "zip_params.pdq.values[0]\n",
    "zip_params.seasonal_pdq.values[0]\n",
    "\n",
    "output_sarima = fit_ARIMA(zip_df[zipcode_osa],order=zip_params.pdq.values[0], seasonal_order= zip_params.seasonal_pdq.values[0] )\n",
    "\n",
    "pred = output_sarima.get_prediction(start=pd.to_datetime('2014-01-01'), dynamic=False)\n",
    "pred_conf = pred.conf_int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_params = output_df[output_df['zipcode']==11218]\n",
    "zip_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_params.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_params['pdq']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_params.pdq.values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot of One-Step-Ahead Forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a plot of the real and forecasted values of the time series to assess how well the model did.  The plot icludes the confidence intervals which in this case overlap the predicted values.  The mean prediction is marked with the orange line.  The uncertainy range is shaded in green.  The uncertainty is due the the random terms that can't be predicted. \n",
    "\n",
    "The central value of the forecast is stored in the .predicted_mean attribute of the pred object.\n",
    "\n",
    "the method .fill_between() produces the shade area between our lower and upper limits.\n",
    "\n",
    "Visually it looks like the model did pretty good at making the predictions for zipcode 11218 because the forecasts align with the true test set values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,5))\n",
    "# Plot observed values\n",
    "ax = train_brk[11218].plot(label='observed')\n",
    "test_brk[11218].plot(label='Test')\n",
    "# Plot predicted values\n",
    "pred.predicted_mean.plot(ax=ax, label='One-step ahead Forecast', alpha=0.9)\n",
    "\n",
    "# Plot the range for confidence intervals\n",
    "ax.fill_between(pred_conf.index,\n",
    "                pred_conf.iloc[:, 0],\n",
    "                pred_conf.iloc[:, 1], color='g', alpha=0.5)\n",
    "\n",
    "# Set axes labels\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('Sale Price')\n",
    "plt.title(f'One-Step-Ahead Forecasting for Zipcode {zipcode_osa}')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check the Model's Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will check the models' accuracy in making the prediction by using the metric RMSE (Mean Squared Error).  RMSE is the standard deviation of the residuals (prediction errors). Residuals are a measure of how far from the regression line data points are.  RMSE is a measure of how spread out these residuals are. It tells us how concentrated the data is around the line of best fit.\n",
    "\n",
    "Model was able to forecast the average daily real estate sales in the test set within 10,607.48 of the real sales.  The sales in this zip code 11218 range from around 1,003,700.00 to 2,202,400.00.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2iNxZriVIcKZ",
    "outputId": "168d9f27-20f7-4435-cabd-4181beaf1fd9"
   },
   "outputs": [],
   "source": [
    "# Get the real and predicted values\n",
    "forecasted_11238 = pred.predicted_mean\n",
    "truth_1128 =test_brk[11218]['1996':]\n",
    "\n",
    "# Compute the root mean square error\n",
    "mse = ((forecasted_11238 - truth_1128) ** 2).mean()\n",
    "print('The Mean Squared Error of our forecasts is {}'.format(round(mse, 2)))\n",
    "#np.sqrt(np.mean((predictions-targets)**2))\n",
    "rmse = np.sqrt(np.mean((forecasted_11238 - truth_1128) ** 2))\n",
    "print('The Root Mean Squared Error of our forecasts is {}'.format(round(rmse, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8dvZmONPccci",
    "outputId": "adeaf1d0-e6e4-4c55-c755-4a16440d04f6"
   },
   "outputs": [],
   "source": [
    "train_brk[zipcode].describe().round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dynamic Forecasting\n",
    "\n",
    "We can make predictioned further than just One-Step-Ahead. We predict One-Step-Ahead and use this predicted value to forecast the next value after that.  We don't don't know the shock term after that so the uncertainy level can grow quickly.\n",
    "\n",
    "The dynamic is set to True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "7V0OghhNIwdW",
    "outputId": "e8da78f8-0f54-4ebf-852b-d0f4c0f7bd93"
   },
   "outputs": [],
   "source": [
    "zipcode_df = 11218\n",
    "zip_params = output_df[output_df['zipcode']== zipcode_df]\n",
    "zip_params.pdq.values[0]\n",
    "zip_params.seasonal_pdq.values[0]\n",
    "\n",
    "output_sarima = fit_ARIMA(zip_df[zipcode_df ],order=zip_params.pdq.values[0] ,seasonal_order= zip_params.seasonal_pdq.values[0] )\n",
    "# Get dynamic predictions with confidence intervals as above \n",
    "pred_dynamic = output_sarima.get_prediction(start=pd.to_datetime('2014-01-01'), dynamic=True,full_results=True)\n",
    "pred_dynamic_conf = pred_dynamic.conf_int()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the observed and forecasted values of the time series, we see that the overall forecasts are accurate even when using Dynamic Forecasting.  Model was able to forecast the average daily real estate sales in the test set within 3724.22 of the real sales.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QYGkYw8CNXp8"
   },
   "outputs": [],
   "source": [
    "\n",
    "def prediction_vis(pred_dynamic,pred_dynamic_conf, y):\n",
    "  # Plot the dynamic forecast with confidence intervals.\n",
    "  plt.figure(figsize=(12,5))\n",
    "  # Plot observed values\n",
    "  ax = y.plot(label='Observed')\n",
    "\n",
    "  # Plot predicted values\n",
    "  pred_dynamic.predicted_mean.plot(ax=ax, label='Dynamic Forecast', alpha=0.9)\n",
    "\n",
    "  # Plot the range for confidence intervals\n",
    "  ax.fill_between(pred_dynamic_conf.index,\n",
    "                  pred_dynamic_conf.iloc[:, 0],\n",
    "                  pred_dynamic_conf.iloc[:, 1], color='g', alpha=0.5)\n",
    "\n",
    "  # Set axes labels\n",
    "  ax.set_xlabel('Date')\n",
    "  ax.set_ylabel('Sale Price')\n",
    "  plt.legend()\n",
    "\n",
    "  return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 362
    },
    "id": "46DeuFE_OC4R",
    "outputId": "2fadcae1-4cc5-4c38-d1b6-d1b826979287"
   },
   "outputs": [],
   "source": [
    "prediction_visual = prediction_vis(pred_dynamic,pred_dynamic_conf,train_brk[zipcode_df])\n",
    "prediction_visual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nVyr6JPa1BHz",
    "outputId": "81164674-c2f6-4f20-f8c9-fcb9917ea27b",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get the real and predicted values\n",
    "forecast_11238 = pred_dynamic.predicted_mean\n",
    "truth_11238 = train_brk[current_zip]#['1996':]\n",
    "\n",
    "# Compute the mean square error\n",
    "mse = ((forecast_11238 - truth_11238) ** 2).mean()\n",
    "print('The Mean Squared Error of our forecasts is {}'.format(round(mse, 2)))\n",
    "#np.sqrt(np.mean((predictions-targets)**2))\n",
    "rmse = np.sqrt(np.mean((forecast_11238 - truth_11238) ** 2))\n",
    "print('The Root Mean Squared Error of our forecasts is {}'.format(round(rmse, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get forecast --- steps ahead in future\n",
    "\n",
    "# prediction = output_sarima.get_forecast(steps=36, dynamic=True)\n",
    "# prediction.predicted_mean\n",
    "\n",
    "# # Get confidence intervals of forecasts\n",
    "# predict_conf = prediction.conf_int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = 36\n",
    "# Get forecast --- steps ahead in future\n",
    "prediction_object = output_sarima.get_forecast(steps=steps, dynamic=True)\n",
    "prediction_object.predicted_mean\n",
    "\n",
    "predict_conf = prediction_object.conf_int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_visual_2 = prediction_vis(prediction_object,predict_conf,zip_df[zipcode_df])\n",
    "prediction_visual_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3bPEYL5i3dBa"
   },
   "source": [
    "### **Return on Investment DataFrame**\n",
    "The method .get_forecast() computes the forecasted values for a specified number of steps ahead.<br>\n",
    "\n",
    "The method .conf_int() gets the confidence intervals of forecasts.<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BayCQRuWawzp"
   },
   "outputs": [],
   "source": [
    "# Get forecast --- steps ahead in future\n",
    "prediction = output_sarima.get_forecast(steps=36, dynamic=True)\n",
    "prediction.predicted_mean\n",
    "\n",
    "# Get confidence intervals of forecasts\n",
    "predict_conf = prediction.conf_int()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gJbRKj4aT2vW"
   },
   "outputs": [],
   "source": [
    "steps = 36\n",
    "# Get forecast --- steps ahead in future\n",
    "prediction_object = output_sarima.get_forecast(steps=steps, dynamic=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mddn9EwEFoq9"
   },
   "outputs": [],
   "source": [
    "def my_function(prediction_object, zip):\n",
    "  \"\"\"\n",
    "  function gets ROI for 1 zipcode \n",
    "  \"\"\"\n",
    "  df_Summary = pd.concat([pd.DataFrame({f'Predicted_Mean {zip}':prediction_object.predicted_mean}), prediction_object.conf_int()],axis = 1)\n",
    "  df_Summary\n",
    "  # my_sample = df_Summary.iloc[[0, -1]].round(3)\n",
    "  my_sample = df_Summary.iloc[[0, -1]].round(3) #1st and last\n",
    "\n",
    "  return my_sample  #df_Summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_output = my_function(prediction_object, zip='11218')\n",
    "my_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def my_roi(cost, current):\n",
    "  \"\"\"  \n",
    "  function to calculate ROI \n",
    "  ROI= \n",
    "  Cost of Investment\n",
    "  Current Value of Investment−Cost of Investment\n",
    "  \"\"\"\n",
    "  return (current - cost) / cost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = my_output.iloc[0,0]\n",
    "current = my_output.iloc[-1,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "current_lower = my_output.iloc[-1,1]\n",
    "current_upper = my_output.iloc[-1,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#upper lower end\n",
    "roi_dic = {}\n",
    "\n",
    "cost = my_output.iloc[0,0]\n",
    "current = my_output.iloc[-1,0]\n",
    "current_lower = my_output.iloc[-1,1]\n",
    "current_upper = my_output.iloc[-1,2]\n",
    "\n",
    "\n",
    "my_roi(cost, current)\n",
    "roi_dic['roi'] = my_roi(cost, current)\n",
    "roi_dic['roi_lower'] = my_roi(cost, current_lower)\n",
    "roi_dic['roi_upper'] = my_roi(cost, current_upper)\n",
    "\n",
    "roi_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_rois={}\n",
    "steps = 36\n",
    "\n",
    "#def zipcode_roi(output_df,):\n",
    "for zipcode in output_df['zipcode'].unique():\n",
    "  pdq = output_df.loc[ output_df['zipcode']==zipcode, 'pdq'].iloc[0] \n",
    "  seasonal = output_df.loc[ output_df['zipcode']==zipcode, 'seasonal_pdq'].iloc[0] \n",
    "  df_ts = zip_df[zipcode]\n",
    "\n",
    "\n",
    "  output_sarima = fit_ARIMA(df_ts, order=pdq, seasonal_order=seasonal)\n",
    "  prediction_object = output_sarima.get_forecast(steps=steps, dynamic=True)\n",
    "  my_output = my_function(prediction_object, zip=zipcode)\n",
    "  \n",
    "  roi_dic = {}\n",
    "\n",
    "  cost = my_output.iloc[0,0]\n",
    "  current = my_output.iloc[-1,0]\n",
    "  current_lower = my_output.iloc[-1,1]\n",
    "  current_upper = my_output.iloc[-1,2]\n",
    "\n",
    "  my_roi(cost, current)\n",
    "  roi_dic['roi'] = my_roi(cost, current)\n",
    "  roi_dic['roi_lower'] = my_roi(cost, current_lower)\n",
    "  roi_dic['roi_upper'] = my_roi(cost, current_upper)\n",
    "\n",
    "  zip_rois[zipcode] = pd.Series(roi_dic)\n",
    "ROI = pd.DataFrame(zip_rois)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roi_df = ROI.T \n",
    "roi_df.reset_index(inplace=True)\n",
    "roi_df.rename(columns={'index':'zipcode'}, inplace=True)\n",
    "roi_df.style.background_gradient()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **ROI Chart**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roi_chart_1 = roi_df.sort_values(by=['roi'],ascending=False)\n",
    "#roi_chart_1 = roi_chart_1.round(3)\n",
    "roi_chart_1.style.background_gradient()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zX67rcJn1RkE"
   },
   "source": [
    "## **Dynamic Forecasting**\n",
    "Forecasting begins 4-1-2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hwDI7SlCJDHn"
   },
   "outputs": [],
   "source": [
    "def forecast_function(output_df, current_zip=None,steps=None):\n",
    "  \n",
    "  # roi_t[roi_t[roi_t.name]== current_zip]\n",
    "  # print('\\n')\n",
    "  zip_params = output_df[output_df['zipcode']==current_zip]\n",
    "  zip_params.pdq.values[0]\n",
    "  zip_params.seasonal_pdq.values[0]\n",
    "\n",
    "  #steps = 36\n",
    "  output_sar = fit_ARIMA(zip_df[current_zip], order=zip_params.pdq.values[0], seasonal_order=zip_params.seasonal_pdq.values[0])\n",
    "  prediction = output_sar.get_forecast(steps=steps, dynamic=True)\n",
    "  prediction.predicted_mean\n",
    "\n",
    "  # Get confidence intervals of forecasts\n",
    "  predict_conf = prediction.conf_int()\n",
    "\n",
    "  return prediction, predict_conf, current_zip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MI_nUjf6zcfK"
   },
   "outputs": [],
   "source": [
    "def forecast_visual(prediction,predict_conf, y, figsize=None):\n",
    "  \"\"\"\n",
    "  prediction-statsmodel object\n",
    "  predict_conf- pd Dataframe\n",
    "  \"\"\"\n",
    "  print(roi_df[roi_df['zipcode']== current_zip])\n",
    "  print('\\n')\n",
    "  # Plot future predictions with confidence intervals\n",
    "  fig,ax = plt.subplots(figsize=figsize)\n",
    "  ax = y.plot(label='Observed') #(10, 8))\n",
    "  prediction.predicted_mean.plot(ax=ax, label='Future Forecast')\n",
    "  ax.fill_between(predict_conf.index,\n",
    "                  predict_conf.iloc[:, 0],\n",
    "                  predict_conf.iloc[:, 1], color='k', alpha=0.25)\n",
    "  \n",
    "    #I added this and can delete  \n",
    "    #ax.axvline(prediction.predicted_mean.index[12])\n",
    "\n",
    "  label_font = {'weight':'bold','size':18}\n",
    "  ax.set_xlabel('Date',fontdict=label_font)\n",
    "  ax.set_ylabel('Home Prices',fontdict=label_font)\n",
    "  ax.set_title(f'Price Forecast for Zipcode: {y.name} /{steps} Months ',fontdict=label_font)\n",
    "\n",
    "  ax.legend(loc=\"upper left\")\n",
    "\n",
    "  return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mo571ImXNkJl"
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "### **Zipcode: 11223**\n",
    "Zipcode 11223 ranks in 1st place for ROI.  The ROI will be 60% on average.<br>\n",
    "If an investment is made for a return on the lower end the return will be 5.27.<br> \n",
    "If a ninvestment is made for a return on the upper end the return will be 86.31.  This will take you into year 2021 and after.<br>\n",
    "Either way it's a good return on the investment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RHe5na7NNYfJ"
   },
   "outputs": [],
   "source": [
    "#prediction, predict_conf, current_zip =  forecast_function(output_df, current_zip=11210, steps=36)\n",
    "#df_test['Btime'].iloc[0]\n",
    "prediction, predict_conf, current_zip =  forecast_function(output_df, current_zip=roi_chart_1['zipcode'].iloc[0], steps=36)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UDHvVgDl4280"
   },
   "outputs": [],
   "source": [
    "test_brk[roi_chart_1['zipcode'].iloc[0]].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IENiexVWDV7n"
   },
   "outputs": [],
   "source": [
    "test_brk[roi_chart_1['zipcode'].iloc[0]].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kEYnbn5D1JVA"
   },
   "outputs": [],
   "source": [
    "forecast_visual_zip = forecast_visual(prediction,predict_conf,test_brk[roi_chart_1['zipcode'].iloc[0]], figsize=(12,8))\n",
    "forecast_visual_zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4vBDuU0xxm7L"
   },
   "source": [
    "### **Zipcode: 11210**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WTrWMrB2PRMa"
   },
   "outputs": [],
   "source": [
    "prediction, predict_conf, current_zip =  forecast_function(output_df, current_zip=roi_chart_1['zipcode'].iloc[1],steps=36)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cQiP3oLuepRY"
   },
   "outputs": [],
   "source": [
    "test_brk[11233].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K5Hix1fpGfLF"
   },
   "outputs": [],
   "source": [
    "test_brk[roi_chart_1['zipcode'].iloc[1]].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8XiBQRYRxwDh"
   },
   "outputs": [],
   "source": [
    "forecast_visual_zip = forecast_visual(prediction,predict_conf,test_brk[roi_chart_1['zipcode'].iloc[1]], figsize=(12,8))\n",
    "forecast_visual_zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UeHWN_hdWGzz"
   },
   "source": [
    "### **Zipcode: 11230**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JVOo_NLvOgur"
   },
   "outputs": [],
   "source": [
    "prediction, predict_conf, current_zip =  forecast_function(output_df, current_zip=roi_chart_1['zipcode'].iloc[2],steps=36)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2MQSYku1fCnt"
   },
   "outputs": [],
   "source": [
    "test_brk[roi_chart_1['zipcode'].iloc[2]].describe().round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3jnMlG4pSCwC"
   },
   "outputs": [],
   "source": [
    "test_brk[roi_chart_1['zipcode'].iloc[2]].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LFU_H54wzNjQ"
   },
   "outputs": [],
   "source": [
    "forecast_visual_zip = forecast_visual(prediction,predict_conf,test_brk[roi_chart_1['zipcode'].iloc[2]], figsize=(12,8))\n",
    "forecast_visual_zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DrTx3pQBSs6k"
   },
   "source": [
    "### **Zipcode: 11224**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lwXaHQI8Shx1"
   },
   "outputs": [],
   "source": [
    "prediction, predict_conf, current_zip =  forecast_function(output_df, current_zip=roi_chart_1['zipcode'].iloc[3],steps=36)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hf8IYy0bfWOO"
   },
   "outputs": [],
   "source": [
    "test_brk[11230].describe().round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PLoTjN18TMbH"
   },
   "outputs": [],
   "source": [
    "test_brk[roi_chart_1['zipcode'].iloc[3]].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3MEd2AyGSiMK"
   },
   "outputs": [],
   "source": [
    "forecast_visual_zip = forecast_visual(prediction,predict_conf,test_brk[roi_chart_1['zipcode'].iloc[3]], figsize=(12,8))\n",
    "forecast_visual_zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "prGAdm_JUMxT"
   },
   "source": [
    "### **Zipcode: 11233**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q-f6sZyHShhC"
   },
   "outputs": [],
   "source": [
    "prediction, predict_conf, current_zip =  forecast_function(output_df, current_zip=roi_chart_1['zipcode'].iloc[4],steps=36)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rwefTf3VfmJR"
   },
   "outputs": [],
   "source": [
    "test_brk[roi_chart_1['zipcode'].iloc[4]].describe().round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wZJNOGZjUGGv"
   },
   "outputs": [],
   "source": [
    "test_brk[roi_chart_1['zipcode'].iloc[4]].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cK924y5iUFto"
   },
   "outputs": [],
   "source": [
    "\n",
    "forecast_visual_zip = forecast_visual(prediction,predict_conf,test_brk[roi_chart_1['zipcode'].iloc[4]], figsize=(12,8))\n",
    "forecast_visual_zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nK-iG68vnSYF"
   },
   "source": [
    "## ***Stationarity***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1_eC0LxVbiVW"
   },
   "source": [
    "### **Zipcode: 11226**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kiyoxXRrbiVa"
   },
   "outputs": [],
   "source": [
    "zip_df[11226].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vs5jehRibiVc"
   },
   "outputs": [],
   "source": [
    "def test_stationarity_1(timeseries, window):\n",
    "    \n",
    "    #Defining rolling statistics\n",
    "    rolmean = timeseries.rolling(window=window).mean()\n",
    "    rolstd = timeseries.rolling(window=window).std()\n",
    "\n",
    "    #Plot rolling statistics:\n",
    "    fig = plt.figure(figsize=(12, 8))\n",
    "    orig = plt.plot(timeseries.iloc[window:], color='blue',label='Original')\n",
    "    mean = plt.plot(rolmean, color='red', label='Rolling Mean')\n",
    "    std = plt.plot(rolstd, color='black', label = 'Rolling Std')\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.title('Rolling Mean & Standard Deviation')\n",
    "    plt.legend(bbox_to_anchor=(1.05,1),loc='upper left')\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "13wkO7v8biVl"
   },
   "outputs": [],
   "source": [
    "#Not mine\n",
    "\n",
    "def dickey_fuller_test_ind_zip(zip_code):\n",
    "    dftest = adfuller(zip_code)\n",
    "\n",
    "    # Extract and display test results in a user friendly manner\n",
    "    dfoutput = pd.Series(dftest[0:4], index=['Test Statistic','p-value','#Lags Used','Number of Observations Used'])\n",
    "    for key,value in dftest[4].items():\n",
    "        dfoutput['Critical Value (%s)'%key] = value\n",
    "    print(dftest)\n",
    "\n",
    "    print ('Results of Dickey-Fuller Test:')\n",
    "\n",
    "    return dfoutput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qyVRzPIeDZ1g"
   },
   "outputs": [],
   "source": [
    "new_dic = {}\n",
    "for col in zip_df.columns:\n",
    "  zip_test = dickey_fuller_test_ind_zip(zip_df[col])\n",
    "  new_dic[col] = zip_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hBFqk98vDwwJ"
   },
   "outputs": [],
   "source": [
    "new_dic[11226]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ziJemkmLbiVo"
   },
   "outputs": [],
   "source": [
    "\n",
    "def dickey_fuller_test_zipcodes(df):\n",
    "    for col in df.columns:\n",
    "        dftest = adfuller(df[col])\n",
    "        dfoutput = pd.Series(dftest[0:4], index=['Test Statistic','p-value','#Lags Used','Number of Observations Used'])\n",
    "        for key,value in dftest[4].items():\n",
    "            dfoutput['Critical Value (%s)'%key] = value\n",
    "        print ('Results of Dickey-Fuller Test:')\n",
    "        \n",
    "        print(dfoutput) \n",
    "        #print(dftest)\n",
    "        print ('\\n')         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qz6HY0rlbiVr"
   },
   "outputs": [],
   "source": [
    "dickey_fuller_test_zipcodes(zip_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lB0sVoPSbiVw"
   },
   "outputs": [],
   "source": [
    "X_1 = zip_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ABPM-PSLbiWW"
   },
   "outputs": [],
   "source": [
    "def stationary_test(df):\n",
    "    rolling_mean = df.rolling(window=12).mean()\n",
    "    rolling_std = df.rolling(window=12).std()\n",
    "\n",
    "    plt.plot(df,color='blue',label='orignal')\n",
    "    plt.plot(rolling_mean, color='red',label='Rolling Mean')\n",
    "    plt.plot(rolling_std, color='green',label='Rolling STD')\n",
    "    plt.legend(loc='best')\n",
    "    plt.title('Rolling Mean and Rolling Standard Deviation')\n",
    "    #plt.show()\n",
    "    result = adfuller(df)\n",
    "    print('ADF statistic: {}'.format(result[0]))\n",
    "    print('p-value: {}'.format(result[1]))\n",
    "    print('Critical Values:')\n",
    "    for key, value in result[4].items():\n",
    "        print('\\t{} : {}'.format(key,value))\n",
    "        \n",
    "    names = ['Test Statistic','p-value','#Lags Used','# of Observations Used']\n",
    "    res  = dict(zip(names,result[:4]))\n",
    "    res['Stationary Results'] = res['p-value']<.05\n",
    "    \n",
    "    return pd.DataFrame(res,index=['AD Fuller Results'])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HqQ1UejybiWg"
   },
   "outputs": [],
   "source": [
    "stationary_test(zip_df[11226])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nfGy_tMXbiWl"
   },
   "source": [
    "###  Zipcode:  11238"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H5_2LrbTbiWl"
   },
   "outputs": [],
   "source": [
    "#brooklyn_zips[11226]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o1-rQeYebiWn"
   },
   "outputs": [],
   "source": [
    "#stationary_test(zip_df[11238])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mEBu8mMMbiWr"
   },
   "source": [
    "### Zipcode:  11215"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RqmZzL9EbiWs"
   },
   "outputs": [],
   "source": [
    "stationary_test(zip_df[11226])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lPfZPRqKbiWu"
   },
   "source": [
    "### Removing Trend\n",
    "#### Log-Transformation (np.log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zmRJNworbiWv"
   },
   "outputs": [],
   "source": [
    "## Log Transform\n",
    "ts3 = np.log(zip_df[11226])\n",
    "#ts3.plot()\n",
    "stationary_test(ts3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GNhy76XObiWz"
   },
   "source": [
    "#### Differencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tW2BO9YabiW0"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "#subtracts the ts 1 step forward from itself. Good way of eliminting trend\n",
    "\n",
    "#below ts centered around 0\n",
    "#we achieved stationarity\n",
    "#eliminating day-to-day patterns\n",
    "\"\"\"\n",
    "ts0 = zip_df[11226].diff().dropna()\n",
    "#ts0.plot()\n",
    "\n",
    "stationary_test(ts0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "997jzmLvbiW4"
   },
   "source": [
    "#### Subtract Rolling Mean "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SRxKzj3HbiW4"
   },
   "outputs": [],
   "source": [
    "## Subtract Rolling mean\n",
    "ts2 = (zip_df[11226] - zip_df[11226].rolling(3).mean()).dropna()\n",
    "#ts2.plot()\n",
    "stationary_test(ts2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "exZwBt4pbiW7"
   },
   "source": [
    "#### Subtract Exponentially-Weighted Mean "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tmUDhjm9biW8"
   },
   "outputs": [],
   "source": [
    "## Subtract Exponentially Weight Mean Rolling mean\n",
    "ts4 = (zip_df[11226] - zip_df[11226].ewm(halflife=7).mean()).dropna()\n",
    "#ts4.plot()\n",
    "stationary_test(ts4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aCZ_c82dbiW_"
   },
   "source": [
    "#### Seasonal Decomposition "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "leunRXJLbiW_"
   },
   "outputs": [],
   "source": [
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "decomp = seasonal_decompose(zip_df[11226])#,model='mul')\n",
    "decomp.plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gkHCCnT2biXB"
   },
   "outputs": [],
   "source": [
    "## Get ADFuller Results for seasonal component\n",
    "stationary_test(decomp.seasonal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dZXqBfP1biXD"
   },
   "outputs": [],
   "source": [
    "## Get ADFuller Results for trend component\n",
    "stationary_test(decomp.trend.dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eMm09mYMbiXF"
   },
   "outputs": [],
   "source": [
    "## Get ADFuller Results for resid component\n",
    "stationary_test(decomp.resid.dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pCKduOGAbiXG"
   },
   "outputs": [],
   "source": [
    "decomp.resid.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5z_0dUz3pHix"
   },
   "source": [
    "## **RNN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UcgF16-aC9HY"
   },
   "outputs": [],
   "source": [
    "df_rnn = zip_df[[11238]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EuApwYLOpNYi"
   },
   "outputs": [],
   "source": [
    "df_rnn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RldYgVvKpb2U"
   },
   "outputs": [],
   "source": [
    "df_rnn.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UICQH8rFpg_7"
   },
   "outputs": [],
   "source": [
    "len(df_rnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k53J6wRSprSk"
   },
   "outputs": [],
   "source": [
    "265-12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OzY_swDSpv9p"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "x_train= x_train.reshape(-1, 1)\n",
    "y_train= y_train.reshape(-1, 1)\n",
    "x_test = x_test.reshape(-1, 1)\n",
    "\"\"\"\n",
    "train = df_rnn.iloc[:253]\n",
    "test = df_rnn.iloc[253:]\n",
    "#test = test.reshape(1, -1)\n",
    "#train= train.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s-KkKABmsVwp"
   },
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CdJPVZ5lp9Vk"
   },
   "outputs": [],
   "source": [
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M6PLWCIvrYe5"
   },
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qOZKOfn3p_hb"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EY9a7CYLqK5v"
   },
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaler.fit(train)\n",
    "scaled_train = scaler.transform(train)\n",
    "scaled_test = scaler.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lVTsgQRqqN9E"
   },
   "outputs": [],
   "source": [
    "scaled_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1BqiRwzBtsyv"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import TimeseriesGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lSgXoTnHtfv5"
   },
   "outputs": [],
   "source": [
    "n_input = 2\n",
    "n_features = 1 #smaller batch sizes lead to better training\n",
    "\n",
    "generator = TimeseriesGenerator(scaled_train, scaled_train, length=n_input, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XPb4lO6muERC"
   },
   "outputs": [],
   "source": [
    "scaled_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Rld4djT0uLxl"
   },
   "outputs": [],
   "source": [
    "len(scaled_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CflS6hSStmxx"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "253 - n_input(2)\n",
    "\n",
    "\"\"\"\n",
    "len(generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ybi9O1Set5KZ"
   },
   "outputs": [],
   "source": [
    "#create model and fit it to the generator object\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense  #for final output later\n",
    "from keras.layers import LSTM #long short term memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ctvwCzruugGf"
   },
   "outputs": [],
   "source": [
    "n_input = 12 #look at full year of data or 12 months before predicting 13th month\n",
    "n_features = 1 #smaller batch sizes lead to better training\n",
    "               #how many columns you have. WE have 1 column which is time stamp for y\n",
    "\n",
    "train_generator = TimeseriesGenerator(scaled_train, scaled_train, length=n_input, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RDdsdHC9ujNE"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(150, activation='relu', input_shape=(n_input, n_features)))\n",
    "#need to aggregate all the neurons to sngle prediciton\n",
    "model.add(Dense(1)) #added single dense neuron which will directly output our prediction\n",
    "model.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_aOIy_gJumuu"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "may want to play around w/number of neurons on LSTM layer\n",
    "\"\"\"\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6uCWYAW-up-U"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "fit tou our training generator\n",
    "more epochs you use hte longer it's going to take to train\n",
    "1 epoch is a single entire run through of training data\n",
    "\n",
    "We get significant reduciton over 1st couple of epochs then around 15 start seeing convergence\n",
    "\n",
    "\"\"\"\n",
    "model.fit_generator(train_generator, epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LMNR-bBZuuHw"
   },
   "outputs": [],
   "source": [
    "model.history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "15Sj6zlbu86t"
   },
   "outputs": [],
   "source": [
    "plt.plot(range(len(model.history.history['loss'])),model.history.history['loss']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W-xSv_-UvGe6"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "evalute on the test data\n",
    "create an evlauation batch\n",
    "our network trains 1 step ahead\n",
    "\n",
    "our network is 12 network steps \n",
    "    then predict step 13\n",
    "    \n",
    "need last 12 points of training data inorder to predict pt. 1 of test data \n",
    "\n",
    "these are last 12 points of training set\n",
    "\"\"\"\n",
    "first_eval_batch = scaled_train[-12:]\n",
    "first_eval_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vgCzkxazvHPl"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "it now has 3 brackets at the top\n",
    "\"\"\"\n",
    "first_eval_batch = first_eval_batch.reshape((1,n_input,n_features))\n",
    "first_eval_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "88VY8RZGvLFj"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "call model on first_eval_batch\n",
    "gives array prediciton\n",
    "means given these 12 points of training data it predicts taht below should be 1st point of test data set\n",
    "\"\"\"\n",
    "model.predict(first_eval_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ULYw3tlmvOZl"
   },
   "outputs": [],
   "source": [
    "scaled_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aDye7VyzvdkR"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "not just predict 1st point in test set but the entire test set\n",
    "how to forecast into the future\n",
    "Forecast using RNN model\n",
    "\"\"\"\n",
    "#hold predicitons\n",
    "test_predictions = []\n",
    "#last n_input points from training set\n",
    "first_eval_batch = scaled_train[-n_input:] \n",
    "#reshape to format of RNN wants, (same format as Timeseriesgenerator \n",
    "current_batch = first_eval_batch.reshape((1,n_input,n_features))\n",
    "\n",
    "#hoe far into the futrue will I forecast: length of test set\n",
    "for i in range(len(test)):\n",
    "    #1time step ahead of historical 12 points\n",
    "    current_pred = model.predict(current_batch)[0] #0 is for formatting \n",
    "    test_predictions.append(current_pred)\n",
    "    \n",
    "    #update current batch to include prediciton\n",
    "    current_batch = np.append(current_batch[:,1:,:],[[current_pred]],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rUu1zNLavhjj"
   },
   "outputs": [],
   "source": [
    "test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XYFfcaWUvlAB"
   },
   "outputs": [],
   "source": [
    "true_predictions = scaler.inverse_transform(test_predictions)\n",
    "true_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jmXWtLZJvnp3"
   },
   "outputs": [],
   "source": [
    "test['Predictions'] = true_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pZDdkE08vrEV"
   },
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l01ERN_JJM48"
   },
   "source": [
    "### **RNN Plot / Sales v Predicted Values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vZrCDEbsvr-G"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "sales v predicted values\n",
    "\"\"\"\n",
    "test.plot(figsize=(12,5));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qYpolS-z3v7q"
   },
   "source": [
    "### **Recommendations**\n",
    "Below are the Brooklyn zipcodes with the predicted Top 5 ROIs which I would recommend investing in:<br>\n",
    "11223  (63%)<br>\n",
    "11210  (59%)<br>\n",
    "11230  (46%)<br>\n",
    "11224  (45%)<br>\n",
    "11233  (42%)<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "ts_model_notebook-12-17-20.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python [conda env:learn-env] *",
   "language": "python",
   "name": "conda-env-learn-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
